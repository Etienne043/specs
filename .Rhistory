iter <- 0
iter.stop <- 15
method <- "rolling"
#prepare data for rolling window forecasts
data <- get.data("E:/Dropbox/PhD/Paper 1/Egor/rolling_PCEPI_12.Rdata") #insert filepath to dataset here
setwd("E:/Dropbox/PhD/Paper 1/Code")
rm(list=ls())
source("source.R")
#prepare data for rolling window forecasts
data <- get.data("E:/Dropbox/PhD/Paper 1/Egor/rolling_PCEPI_12.Rdata") #insert filepath to dataset here
rm(list=ls())
source("source.R")
#prepare data for rolling window forecasts
data <- get.data("E:/Dropbox/PhD/Paper 1/Egor/rolling_PCEPI_12.Rdata") #insert filepath to dataset here
#prepare data for rolling window forecasts
data <- get.data("E:/Dropbox/PhD/Paper 1/Datasets/data.csv") #insert filepath to dataset here
cleaned <- data$clean
transformed <- data$transformed
codes <- data$codes
#set up forecasting function for parallel computing
forecast <- function(i){
#gather data for estimation
if(method=="rolling"){
q <- i
}else if(method=="recursive"){
q <- 1
}
#Define data sample
t <- window+h
x.train <- x[q:(i-1+window),]
y.l <- y.lags[q:(i-1+window),]
y.train <- y.h[q:(i-1+window)]
x.PC <- x[q:(i-1+t),]
x.test <- x[i-1+t,]
y.test <- y.lags[i-1+t,]
y.f <- y.h[i-1+t]
n <- length(y.train)
#Define object to store results
pred <- vector()
MSFE <- vector()
nvar <- vector()
lags <- vector()
coefs <- list()
names <- NULL
count <- 0
#AR
count <- count+1
names <- c(names,"AR")
tmp <- AR(y.train,y.l,"BIC")
p <- tmp$p
coef <- tmp$beta
yhat <- matrix(c(1,y.test[0:p]),nrow=1)%*%coef
pred[count] <- yhat
MSFE[count] <- (y.f-yhat)^2
nvar[count] <- num.var(coef[-1])
coefs[[count]] <- coef
lags[count] <- p
#shrinkage estimators
algos <- c("ridge","las","adalas","en","adaen")
ICs <- c("BIC","AIC","CV")
for(j in 1:length(algos)){
for(i in 1:length(ICs)){
count <- count+1
#Define algorithm name and IC
name <- paste(algos[j],ICs[i],sep="")
names <- c(names,name)
if((name %in% c("ridgeBIC","ridgeAIC")) & ncol(x.train)+p.max > (length(y.train)-15)){
#BIC and AIC don't work for ridge in high dimension, only CV allowed
#Perform estimation
pred[count] <- NA
MSFE[count] <- NA
nvar[count] <- NA
coefs[[count]] <- NA
lags[count] <- NA
}else{
#Perform estimation
tmp <- GLMN.emp(y.train,x.train,y.l,type=algos[j],IC=ICs[i],init = "ridge",IC.lag="BIC")
p <- tmp$lags
coef <- tmp$beta
yhat <- t(c(1,x.test,y.test[0:p]))%*%coef
pred[count] <- yhat
MSFE[count] <- (y.f-yhat)^2
nvar[count] <- num.var(coef[-1])
coefs[[count]] <- coef
lags[count] <- p
#get index for PPC based on lasBIC and lasAIC
if(name=="lasBIC"){
PPC.BIC <- head(coef[-1],ncol(x.train)) != 0
}else if(name=="lasAIC"){
PPC.AIC <- head(coef[-1],ncol(x.train)) != 0
}
}
}
}
BN <- c("PC1","PC2","PC3","IC1","IC2","IC3")
ABC <- paste("ABC",BN[4:6],sep="_")
infcrit <- c(1,4,BN,ABC,"onatski","ER","GR")
#PC
PC.full <- PrC(x.PC,factors)$PC
for(l in 1:length(infcrit)){
count <- count+1
crit <- infcrit[l]
name <- paste("PC",crit,sep="-")
names <- c(names,name)
if(crit %in% c("1","4")){
k <- as.numeric(crit)
}else if(crit %in% ABC){
crit <- unlist(strsplit(crit,"ABC_"))[2]
k <- select.ABC(x.PC,PC.fun=PrC,factors=10,type=crit)
}else{
k <- select.f(x.PC,PC.full,type=crit)
}
PC <- PC.full[,1:k]
tmp <- PC.emp(y.train,y.l,head(PC,length(y.train)))
p <- tmp$lags
coef <- tmp$beta
yhat <- t(c(1,tail(PC,1),y.test[0:p]))%*%coef
pred[count] <- yhat
MSFE[count] <- (y.f-yhat)^2
nvar[count] <- num.var(coef[-1])
lags[count] <- p
}
weighting <- c("ruleI","rule0","rule1","rule2")
for(j in 1:length(weighting)){
PC.full <- WPrC(x.PC,rule=weighting[j],factors = factors)$PC
for(l in 1:length(infcrit)){
count <- count+1
crit <- infcrit[l]
name <- paste("PC",weighting[j],sep="")
name <- paste(name,crit,sep="-")
names <- c(names,name)
if(cols(PC.full)>1){
if(crit %in% c("1","4")){
k <- min(cols(PC.full),as.numeric(crit))
}else if(crit %in% ABC){
crit <- unlist(strsplit(crit,"ABC_"))[2]
k <- select.ABC(x.PC,PC.fun=PrC,factors=10,type=crit)
}else{
k <- select.f(x.PC,PC.full,type=crit,k.max=col(PC.full))
}
PC <- PC.full[,1:k]
}else{
PC <- PC.full
}
tmp <- PC.emp(y.train,y.l,head(PC,length(y.train)))
p <- tmp$lags
coef <- tmp$beta
yhat <- t(c(1,tail(PC,1),y.test[0:p]))%*%coef
pred[count] <- yhat
MSFE[count] <- (y.f-yhat)^2
nvar[count] <- num.var(coef[-1])
lags[count] <- p
}
}
#PPC-BIC
if(sum(PPC.BIC)==0){
PC <- NULL
}else if(sum(PPC.BIC)==1){
PC <- PC.full <- x.PC[,PPC.BIC]
}else{
PC.full <- PrC(x.PC[,PPC.BIC],factors = min(sum(PPC.BIC),factors))$PC
}
for(l in 1:length(infcrit)){
count <- count+1
crit <- infcrit[l]
name <- paste("PPC.BIC",crit,sep="-")
names <- c(names,name)
if(cols(PC.full)>1){
if(crit %in% c("1","4")){
k <- min(as.numeric(crit),sum(PPC.BIC))
}else if(crit %in% ABC){
crit <- unlist(strsplit(crit,"ABC_"))[2]
k <- select.ABC(x.PC,PC.fun=PrC,factors=min(sum(PPC.BIC),factors),type=crit)
}else{
k <- select.f(x.PC,PC.full,type=crit)
}
PC <- PC.full[,1:k]
}
tmp <- PC.emp(y.train,y.l,head(PC,length(y.train)))
p <- tmp$lags
coef <- tmp$beta
yhat <- t(c(1,tail(PC,1),y.test[0:p]))%*%coef
pred[count] <- yhat
MSFE[count] <- (y.f-yhat)^2
nvar[count] <- num.var(coef[-1])
lags[count] <- p
}
#PPC-AIC
if(sum(PPC.AIC)==0){
PC <- NULL
}else if(sum(PPC.AIC)==1){
PC <- PC.full <- x.PC[,PPC.AIC]
}else{
PC.full <- PrC(x.PC[,PPC.AIC],factors = min(sum(PPC.AIC),factors))$PC
}
for(l in 1:length(infcrit)){
count <- count+1
crit <- infcrit[l]
name <- paste("PPC.AIC",crit,sep="-")
names <- c(names,name)
if(cols(PC.full)>1){
if(crit %in% c("1","4")){
k <- min(as.numeric(crit),sum(PPC.AIC))
}else if(crit %in% ABC){
crit <- unlist(strsplit(crit,"ABC_"))[2]
k <- select.ABC(x.PC,PC.fun=PrC,factors=min(sum(PPC.AIC),factors),type=crit)
}else{
k <- select.f(x.PC,PC.full,type=crit)
}
PC <- PC.full[,1:k]
}
tmp <- PC.emp(y.train,y.l,head(PC,length(y.train)))
p <- tmp$lags
coef <- tmp$beta
yhat <- t(c(1,tail(PC,1),y.test[0:p]))%*%coef
pred[count] <- yhat
MSFE[count] <- (y.f-yhat)^2
nvar[count] <- num.var(coef[-1])
lags[count] <- p
}
#Determine number of dynamic factors
M <- ceiling(sqrt(nrow(x.PC)))
q <- select.df(x.PC,J=3,q.max=10,type="log")
#FHLR1
count <- count+1
names <- c(names,"FHLR1")
PC <- FHLR(x.PC,M,1,1)$PC
ol <- nrow(x.PC) - rows(PC)
tmp <- PC.emp(y.train[(1+ol):n],y.l[(1+ol):n,],head(PC,length(y.train[(1+ol):n])))
p <- tmp$lags
coef <- tmp$beta
yhat <- t(c(1,tail(PC,1),y.test[0:p]))%*%coef
pred[count] <- yhat
MSFE[count] <- (y.f-yhat)^2
nvar[count] <- num.var(coef[-1])
lags[count] <- p
#FHLR4
count <- count+1
names <- c(names,"FHLR4")
PC <- FHLR(x.PC,M,q,4)$PC
ol <- nrow(x.PC) - rows(PC)
tmp <- PC.emp(y.train[(1+ol):n],y.l[(1+ol):n,],head(PC,length(y.train[(1+ol):n])))
p <- tmp$lags
coef <- tmp$beta
yhat <- t(c(1,tail(PC,1),y.test[0:p]))%*%coef
pred[count] <- yhat
MSFE[count] <- (y.f-yhat)^2
nvar[count] <- num.var(coef[-1])
lags[count] <- p
#FHLRA
count <- count+1
names <- c(names,"FHLRA")
if(q==1){
pred[count] <- pred[count-2]
MSFE[count] <- MSFE[count-2]
nvar[count] <- nvar[count-2]
lags[count] <- lags[count-2]
}else if(q==4){
pred[count] <- pred[count-1]
MSFE[count] <- MSFE[count-1]
nvar[count] <- nvar[count-1]
lags[count] <- lags[count-1]
}else{
PC <- FHLR(x.PC,M,q,factors)$PC
ol <- nrow(x.PC) - rows(PC)
tmp <- PC.emp(y.train[(1+ol):n],y.l[(1+ol):n,],head(PC,length(y.train[(1+ol):n])))
p <- tmp$lags
coef <- tmp$beta
yhat <- t(c(1,tail(PC,1),y.test[0:p]))%*%coef
pred[count] <- yhat
MSFE[count] <- (y.f-yhat)^2
nvar[count] <- num.var(coef[-1])
lags[count] <- p
}
#obtain output
results <- rbind(pred,MSFE,nvar,lags)
colnames(results) <- names
list(results=results,coefs=coefs,actual=y.f)
}
#Create clusters and fix RNG seed
cl <- makeCluster(detectCores()-1)
clusterSetRNGStream(cl,iseed=2345678)
#Set up parameters for computation
var.names <- c("RPI","INDPRO","CMRMTSPLx","PAYEMS","PPIFGS","CPIAUCSL","CPIULFSL","PCEPI")
names <- c("Real Production Income",
"Total Industrial Production",
"Real Manufacturing and Trade Sales",
"Employees - non-agricultural",
"Producer Index - Finished Goods",
"Consumer Price Index - Total",
"Consumer Price Index - Less Food",
"PCE Price Deflator")
hs <- c(1,6,12,24) #Forecast horizon
factors <- 10
p.max <- 6 #Maximum number of AR lags
window <- 120
iter <- 0
iter.stop <- 15
method <- "rolling"
stopCluster(cl)
a=b=1
h <- hs[a]
iter <- iter+1
#Obtain variables used for estimation
name <- y.name <- var.names[b]
y.ind <- which(colnames(cleaned)==name)
code <- codes[y.ind]
y.tr <- 1200*transformed[,y.ind]
y.lags <- embed(y.tr,6)
x <- tail(transformed[,-y.ind],nrow(y.lags))
y.raw <- cleaned[,y.ind]
y.h <- vector()
end <- length(y.raw)-p.max-1-h
if(code==5){
for(j in 1:end){
y.h[j] <- 1200/h*log(y.raw[p.max+1+h+j]/y.raw[p.max+1+j])
}
}else if(code==6){
for(j in 1:end){
y.h[j] <-  1200/h*log(y.raw[p.max+1+h+j]/y.raw[p.max+1+j]) - 1200*log(y.raw[p.max+h+j]/y.raw[p.max+j])
}
}
x <- head(x,length(y.h))
#start parallel forecast
varlist <- ls()
clusterSetRNGStream(cl,iseed=123457)
clusterExport(cl=cl,c(varlist,"mvrnorm","glmnet","cv.glmnet"))
forecast(1)
warnings()
#gather data for estimation
if(method=="rolling"){
q <- i
}else if(method=="recursive"){
q <- 1
}
#Define data sample
t <- window+h
x.train <- x[q:(i-1+window),]
y.l <- y.lags[q:(i-1+window),]
y.train <- y.h[q:(i-1+window)]
x.PC <- x[q:(i-1+t),]
x.test <- x[i-1+t,]
y.test <- y.lags[i-1+t,]
y.f <- y.h[i-1+t]
n <- length(y.train)
#Define object to store results
pred <- vector()
MSFE <- vector()
nvar <- vector()
lags <- vector()
coefs <- list()
names <- NULL
count <- 0
#AR
count <- count+1
names <- c(names,"AR")
tmp <- AR(y.train,y.l,"BIC")
p <- tmp$p
coef <- tmp$beta
yhat <- matrix(c(1,y.test[0:p]),nrow=1)%*%coef
pred[count] <- yhat
MSFE[count] <- (y.f-yhat)^2
nvar[count] <- num.var(coef[-1])
coefs[[count]] <- coef
lags[count] <- p
i=1
#gather data for estimation
if(method=="rolling"){
q <- i
}else if(method=="recursive"){
q <- 1
}
#Define data sample
t <- window+h
x.train <- x[q:(i-1+window),]
y.l <- y.lags[q:(i-1+window),]
y.train <- y.h[q:(i-1+window)]
x.PC <- x[q:(i-1+t),]
x.test <- x[i-1+t,]
y.test <- y.lags[i-1+t,]
y.f <- y.h[i-1+t]
n <- length(y.train)
#Define object to store results
pred <- vector()
MSFE <- vector()
nvar <- vector()
lags <- vector()
coefs <- list()
names <- NULL
count <- 0
#AR
count <- count+1
names <- c(names,"AR")
tmp <- AR(y.train,y.l,"BIC")
p <- tmp$p
coef <- tmp$beta
yhat <- matrix(c(1,y.test[0:p]),nrow=1)%*%coef
pred[count] <- yhat
MSFE[count] <- (y.f-yhat)^2
nvar[count] <- num.var(coef[-1])
coefs[[count]] <- coef
lags[count] <- p
#shrinkage estimators
algos <- c("ridge","las","adalas","en","adaen")
ICs <- c("BIC","AIC","CV")
for(j in 1:length(algos)){
for(i in 1:length(ICs)){
count <- count+1
#Define algorithm name and IC
name <- paste(algos[j],ICs[i],sep="")
names <- c(names,name)
if((name %in% c("ridgeBIC","ridgeAIC")) & ncol(x.train)+p.max > (length(y.train)-15)){
#BIC and AIC don't work for ridge in high dimension, only CV allowed
#Perform estimation
pred[count] <- NA
MSFE[count] <- NA
nvar[count] <- NA
coefs[[count]] <- NA
lags[count] <- NA
}else{
#Perform estimation
tmp <- GLMN.emp(y.train,x.train,y.l,type=algos[j],IC=ICs[i],init = "ridge",IC.lag="BIC")
p <- tmp$lags
coef <- tmp$beta
yhat <- t(c(1,x.test,y.test[0:p]))%*%coef
pred[count] <- yhat
MSFE[count] <- (y.f-yhat)^2
nvar[count] <- num.var(coef[-1])
coefs[[count]] <- coef
lags[count] <- p
#get index for PPC based on lasBIC and lasAIC
if(name=="lasBIC"){
PPC.BIC <- head(coef[-1],ncol(x.train)) != 0
}else if(name=="lasAIC"){
PPC.AIC <- head(coef[-1],ncol(x.train)) != 0
}
}
}
}
warnings()
tmp
coefs
library(specs)
library(specs)
library(rbenchmark)
library(microbenchmark)
library(Rcpp)
library(RcppArmadillo)
library(specs)
set.seed(1234)
#DGP function
VECM <- function(alpha,beta,t){
#Obtain dimensions
n <- nrow(alpha)
#Generate covariance matrix
m.ind <- matrix(rep(seq(1,n),n),n,n)
S <- exp(log(0.6)*abs(m.ind-t(m.ind))) #correlation matrix
#Generate errors and starting values
C <- t(chol(S))
e <- matrix(rnorm(n*t),n,t)
eps <- C%*%e
#obtain VAR coefficients
Pi <- alpha%*%t(beta)
P <- (Pi+diag(n))
phi <- 0.4*diag(n)
P <- cbind(P+phi,-phi)
#Check roots
ps <- ncol(P)
p.comp <- rbind(P,cbind(diag(n),matrix(0,n,n)))
roots <- abs(eigen(p.comp)$values)
max.root <- max(roots)
if(max(roots)> (1+1e-6)){
stop(paste("The largest absolute root is ",max(roots),sep=""))
}
#Generate VECM
z <- matrix(0,n,2)
for(i in 1:t){
z.new <- P%*%as.vector(z[,(1+i):i]) + eps[,i]
z <- cbind(z,z.new)
}
z <- t(z[,-c(1:2)])
#Obtain parameters for the conditional model
pi0 <- as.numeric(t(S[1,-1])%*%solve(S[-1,-1]))
pi0[abs(pi0)<1e-15] <- 0 #numerical inaccuracies
delta <- as.numeric(t(c(1,-pi0))%*%Pi)
pi1 <- as.numeric(t(c(1,-pi0))%*%phi)
pi1[abs(pi1)<1e-15] <- 0 #numerical inaccuracies
#Output
list(alpha=alpha,beta=beta,delta=delta,pi0=pi0,pi1=pi1,z=z)
} #Create simple VECM(1)
#Get data
r <- 3; t <- 1000
beta <- rbind(kronecker(diag(1,r),c(1,rep(-1,4)))[,1:r])
beta <- matrix(c(1,rep(-1,4),rep(0,10)),ncol=1)
alpha <- -0.5*beta
data <- VECM(alpha,beta,t)
z <- data$z; delta <- data$delta
p <- 3                  #number of lagged differences
y <- z[,1]              #dependent variable in lvls
x <- z[,-1]             #independent variables in lvls
k.delta <- 1            #weight exponent for delta
k.pi <- 1
#system.time({test <- specs(y,x,20,"both")}) #long lag length
test <- specs(y,x,2,"none",T,"none")
test <- specs(y,x,2,"none",F,runif(59,0,1000))
library(devtools)
devtools::build()
install.packages("rhub")
library(rhub)
validate_email()
check()
check()
